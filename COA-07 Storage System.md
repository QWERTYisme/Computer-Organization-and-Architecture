### 存储系统的层次结构

#### 存储系统的基本要素

- 功能分类
  - 主存（内存）：半导体存储器，存放当前正在执行的程序和数据。
  - 辅存（外存）：磁盘、磁带、光盘，存放当前不在运行的大量程序和数据。

- 访问方式
  - 随机存储器：可随机访问任一单元。
  - 串行存储器：访问指定信息所需时间与信息所在位置有关。
- 关键问题
  - 现实问题：存储系统是整个计算机系统的性能瓶颈。
  - 目标：解决对存储器要求容量大、速度快、成本低三者之间的矛盾。
  - 解决方案：为解决三者间的矛盾，**目前通常采用层次结构存储系统**。



#### 主要技术指标

- 存储容量（S）：可存储的二进制位数，单位常为字节（B）。
- 存取速度（B）：常用存取时间、存取周期表示。
  - 存取时间（TA）：指存储器从收到命令到完成操作所需的时间。
  - 存取周期（TM）：指连续访问存储器的最小时间间隔，TM=TA+T恢复。
- 传输速度：常用存储器带宽（BM）表示。
  - 定义：指存储器的最大数据传输率，单位常为Mbps。
  - 公式：BM=W/TM，W为数据宽度（数据引脚位数）。

> 思考：某1K×8位SRAM芯片的存储周期 为100ns，该芯片的带宽是多少？



#### 层次结构的引入

现实问题：大容量 vs 高速度、高速度 vs 低价格。

程序访问的局部性原理：程序运行时，访问指令和数据所呈现出的相对簇聚的现象。

- 时间局部性：最近访问过的信息，将会被再次访问。
- 空间局部性：最近访问过信息的相邻信息，将会被访问。

解决方案：层次结构存储系统。

**快速存储器+慢速存储器**

- 快速存储器→近期常用数据、容量小
- 慢速存储器→近期为用数据、容量大



#### 层次结构的组成

基本组成：多种存储器{M1, M2, …, Mn}级联（上下级关系）。

参数要求： SM1<<SM2<<…<<SMn，TM1<<TM2<<…<<TMn 。

内容要求：上级存储器中的信息为下级存储器中信息的**副本**。

传递要求：各级存储器之间的信息传递是**透明**的，即存储系统外部不可见、可见的是存取周期不固定。



#### 多级存储体系结构的实现和比较

从寄存器到L1、L2、L3缓存，再到内存，固态硬盘、机械硬盘，到网络云存储空间，**访问速度越来越慢，每位的价格越来越便宜，存储容量越来越大**



#### 常见的层次结构

##### 以“主存”为中心，常为“Cache-主存-辅存”三层结构。

- **高速缓冲存储器（Cache）**

  用途：高速存取指令和数据，可与CPU速度
  匹配

  特点：存取速度快 存储容量小

- **主存储器（主存）**

  用途：存放计算机运行期间的大量程序和数
  据

  特点：存取速度较快 存取容量大

- **辅助存储器（辅存）**

  用途：存放系统程序和大型数据文件及数据
  库

  特点：存储容量大 位成本低

##### Cache-主存层次

目标：解决**主存速度**问题（Cache的速度，主存的容量）。

Cache引入：解决CPU的主存的速度差距，提高整机的运算速度。

Cache特点：存储速度快，容量小，存储控制和管理由硬件实现。

数据传递

- CPU <==> Cache：以字为单位。
- Cache <==> 主存：以块为单位，一个块由若干个字组成，是定长的。

实现：Cache中，每个块外加有一个**标记**，指明它是主存的哪一块的**副本**。

问题：**如何实现Cache和主存的高效映射？**

##### 主存-辅存层次

目标：解决主存容量问题（主存的速度，辅存的容量）

- 主存：半导体存储器组成。

  特点：速度快，但容量受限、单位成本高、断电易丢失。

- 辅存：磁盘、光盘。

  特点：容量大，单位成本低，信息长久保存，但存取速度慢。

数据传递

- 辅存只与主存进行数据交换。
- 主存 <==> 辅存：以段、页或两者结合为单位。

实现：虚拟存储器，实现容量扩展和进程管理等。

问题：**如何实现虚拟存储器和主存的高效映射？**

### 高速缓冲存储器（Cache）

#### Cache的工作原理

组成：小容量的SRAM存储器和高速缓存控制器组成。

位置：Cache存储器介于CPU和主存之间。

性能指标

- 命中率：H ＝ Nc /(Nc＋Nm) ＝ 命中Cache次数/访存总次数。

- 平均访问时间：指Cache-主存层次完成访存操作平均所用时间。

  TA ＝ H·Tc＋(1－H)(Tc＋Tm) ＝ Tc＋(1－H)Tm ＝ T命中＋(1－H)T缺失



#### Cache-主存的层次管理要求

目标：**减小TA**， TA＝Tc＋(1－H)Tm 。

方法

- 提高H：利用程序**访问局部性** -> **相邻信息**放在Cache中。
- 减小Tm：利用**突发传输**模式

Cache-主存的信息交换单位：块（Block，又称字块）

- 块大小：n个存储字（即主存字[主存单元中的信息]，n为常数）。
- 块大小的确定：固定值，H较高时的n，通常为8个机器字长。



#### Cache存储空间的编址

单位：采用主存的编址单位，即**主存字**。（Cache是主存的缓冲器）

Cache-主存的信息交换管理

- 归一化：主存和Cache的存储空间，都**划分**成多个大小为**块**的区域。
- Cache每行需设置**有效位（V）**和**标记（Tag）**表示本行**是/否空闲**和**数据来自的主存块**。



#### Cache存储空间的组织

结构：Cache是行的数组，每行包含缓存块信息、管理信息。

容量：Cache数据区的容量称为Cache容量；Cache数据区、管理区容量之和称为Cache总容量。

缓存块：大小、编址单位都与主存块相同。

- 块内：地址位数＝log2(块大小÷主存字大小) 。
- 块间：一个块称为Cache的一行 -> Cache行数＝Cache容量÷块大小。

Cache命中：是否命中，通过比较**有效位**和**标记**来实现。



#### Cache工作的基本过程

完整访问过程：①地址**变换**，②**访问**Cache，③数据**写回**主存。

相关技术：映射规则、替换算法、写策略。

实现要求：**全部由硬件完成**（高速目标的要求）。



#### Cache的读操作

基本过程

- 命中：如果数据在Cache中(命中Hit)，就直接对Cache进行读操作，与主存无关。
- 不命中：如果Cache不命中(Miss)，则仍需访问主存，并把该块信息一次从主存调入Cache。

相关技术：替换算法。

- 所解决的问题：从主存读出新的字块调入Cache存储器时，如果遇到Cache存储器中相应的位置 已被其他字块占有，那么就必须去掉一个旧的字块，让位于一个新的字块。
- 替换规则：替换应该遵循一定的规则，最好能使被替换的字块是**下一段时间内估计最少使用的**。 这些规则称为替换策略或替换算法，由替换部件加以实现。



#### Cache的写操作与更新策略

基本过程：更新**Cache数据**和**主存数据**，后者的更新时机可选。

相关技术：写策略。

- 写通法（全写法、直达法）：命中时同时写Cache和主存，未命中时直接写主存。
  - 优点：无需设置修改位及判断逻辑。
  - 缺点：降低了Cache的功效。
- 写回法：命中时只写Cache而不立即写主存，只有当此行被换出时才写回主存。
  - 优点：减少了访存次数。
  - 缺点：存在不一致的隐患，需设置修改位及判断逻辑。



#### Cache的组织和结构

基本结构：存储体、地址映射机构、替换机构、读写机构。

访问过程的组织：见ppt第20页

地址映射机构：由有效位（V）和标记（Tag）、比较器组成。

- 映射机制：确定Tag位数和每次的查找范围（候选行）。

  组织：主存块号＝<标记, 索引>（标记对应Tag位数，索引对应查找范围）

- 查找机构：判断是否命中，获得目标行地址或空闲地址

  实现：候选行的Tag＝主存地址中的标记 **且** 有效位＝1？

替换机构：由状态位、状态更新及行选择部件等组成。

- 更新机制：**更新**候选行的状态（取决于**替换算法**）。
- 选择机构：在候选行**选择牺牲行**，**腾空**行中数据。

读写机构：存储器访问部件。

- 功能：读出主存块、块/字写回主存（取决于**写策略**）。



#### Cache的地址映射

任务：确定一个主存块可放到Cache的**哪些行**。

性能指标：地址变换的**速度与成本**，块调入时的**冲突率**。

分类：不同的映射规则。

- 直接映射（Direct Mapping）：主存块i只可以放到Cache的**某个行**j中。
- 全相联映射（Fully Associate Mapping）：主存块i可以放到Cache的**任意行**j中。
- 组相联映射（Set Associate Mapping）：将Cache的行分组，每个组有n个行；主存块i可以放 到Cache**某个组**j的**任意行**中。



##### 直接映射

映射规则：主存块i只可放到Cache的某个行j中，j＝i mod G。

- 其中，j是Cache的行（块）号，i是主存的块号，G为Cache的行数。

实现：把主存分成若干个区，每个区与Cache大小相同，区内按照Cache进行同样的分块。

- 主存地址：<区号，区内块号，块内地址>。
- Cache地址：<行（块）号，块内地址>。

标记选定：索引＝区内块号，**标记＝主存块号－索引＝区号**。

本质：多对一的映射关系，一个主存块只能映射到Cache的一个特定块位置上去。

地址变换：Cache中的候选行只有1行（索引值＝行号）。

- 命中条件：主存地址中的**区号**＝候选行的**标记Tag**，且有效位V＝1时。
- 变换结果：Cache地址＝<命中行号,**块内地址**>。

特征：地址变换速度**最快**、成本**最低**，但块调入时冲突率**最高**。

优点：地址变换简单、速度快，可直接由主存地址提取Cache地址，确定所需字块是否已在Cache中。

缺点：不够灵活，主存的多个字块只能对应唯一的Cache字块。因此，即使Cache别的地址空闲也不 能占用，使得Cache存储空间得不到充分利用，降低了命中率。



##### 全相联映射

映射规则：主存块i可以放到Cache的**任意行**j中，j∈{0,1,…,G-1}。

实现：除块内地址外，主存地址与Cache地址无必然联系。

- 主存地址：<主存块号，块内地址>。
- Cache地址：<行（块）号，块内地址>。

标记选定：没有索引，标记＝主存块号(m位)。

地址变换：候选行有G个(Cache所有行)。

- 命中条件：地址中的主存块号与候选行的Tag比较，相等且V＝1时命中。

- 比较方案：

  ①1个比较器，分时比较(T比较＝G·Δt)；

  **②G个比较器，同时比较(T比较＝Δt)。**

特征：块调入时冲突率**最低**，地址变换速度**较快**，但成本**最高**。

优点：映射灵活，允许主存中的每一个字块映射到Cache的任何一个字块位置上，可**充分利用**Cache 的存储空间。

缺点：成本高，访问Cache时，需要和Cache的全部标记进行“比较”才能判断出所访主存地址的内 容是否已在Cache中，几乎无法实现。



##### 组相联映射

映射规则：将Cache行分组，每组有n行；主存块i可放到Cache中某个组j的任意行，j＝i mod G/n。

实现：把主存分成若干个群，每个群与Cache的一个分组大小相同。

- 主存地址：<群号，群内块号，块内地址>。
- Cache地址：<组号，组内行号，块内地址>。

标记选定：索引＝群内块号，**标记＝主存块号－索引**＝群号。

地址变换：候选行有n个(组内所有行)。

- 命中条件：主存地址中的群号等于某候选行的Tag，且V＝1时。
- 变换结果：Cache地址＝<命中行号,**块内地址**> 。

特征：块调入时冲突率**较低**，地址变换速度**较快**、成本**较低**。

优点：映射相对灵活，组间为直接映射，组内的字块为全相联映射。

缺点：成本略高，但**可接受**。访问Cache时仅需比较n个“标记”即可判断访存内容是否在Cache中。



##### 映射的总结

映射方式的抽象：都可看作组相联映射。

-  相联度：指一个主存块可映射到的Cache行数，即候选行数(如直接、全相联、组相联映射的相联 度分别为1、G、n)。

映射方式的应用：常为**组相联方式**。



#### Cache的替换算法

任务：从候选行中**找出**一个牺牲块（行）。

- 直接映射：没得选，候选行仅1行。
- 全相联/组相联映射：受限于替换算法。

性能指标：对命中率的**影响程度**、算法的**实现开销**。

- 影响程度：替换是否遵循程序访问局部性。
- 目标：不影响后续访问的命中率。

分类：不同的替换策略。

- 随机算法（Random，RAND）：**随机**选择一个块作为牺牲块。
- 先进先出算法（First In First Out，FIFO）：选择**最早调入**的块作为牺牲块。
- 最近最少使用算法（Least Recently Used，LRU）：选择**近期最少使用**的块作为牺牲块。

应用：LRU算法，或其改进算法。



##### 随机算法（RAND）

基本思想：**随机**选择一个块作为牺牲块。

实现方法：候选行中所有行共设置**1个随机数发生器**。

性能分析

- 命中率：随机。
- 实现开销：最低（1个发生器）→ 适合**全相联映射**Cache



##### 先进先出算法（FIFO）

基本思想：选择**最早调入的**块作为牺牲块。

实现方法

- 硬件配置：候选行中每行设置1个**计数器CNT**。
- 块次序表示方法：通常：越早调入、CNT值越大。
- 牺牲块选择方法：CNT值最大的块。
- 块次序更新方法：调入行的CNT←0，其余行的CNT←(CNT)＋1（**饱和运算**）。
- 块次序更新时机：块调入时。

性能分析

- 命中率：随机（块调入次序≠访问次序、未遵循局部性）。
- 较大（需G个k位计数器）→ 适合**组相联映射**Cache



##### 最近最少使用算法（LRU）

基本思想：选择**近期最少使用的**块作为牺牲块。

实现方法：与FIFO算法基本相同

- 相同点：硬件配置，牺牲块选择方法，块次序更新方法。
- 不同点：块次序表示方法（越早**访问**，CNT值越大），块次序更新时机（块**访问**时）。
- 命中率：**随相联度增大**而提高(各块次序＝访问次序)。
- 实现开销：较大（同FIFO算法）→ 适合组相联映射Cache



#### Cache的写策略

任务：确定写操作的数据**何时写回**主存（首先于写策略）。

性能指标：对TA的**影响程度**      [TA＝T命中＋(1－H)T缺失]

分类：不同的写回时机。

- 写通法（Write Through）：**立即**写回主存。
- 写回法（Write Back）：**稍后**写回主存。

应用：常采用写回法（命中率高、占用总线少）。



##### 写通法（Write Through）

基本思想：立即写（以保持一致性）。

- 写命中时：数据写入Cache，**同时写入**主存；
- 写缺失时：数据直接写入主存，目标块不调入Cache。

硬件组织：无需增加硬件。

特点：已保持Cache和主存数据的一致性，但写命中延迟大，总线占用多。



##### 写回法（Write Back）

基本思想：稍后写（以优化T命中）。

- 写命中时：数据只写入Cache，**不写入**主存；
- 写缺失时：目标块调入Cache，数据**只写入**Cache。
- 块替换时：**改写过的**缓存块才写回主存。

硬件组织：Cache行中设置**修改位（脏位）**，表示块的改写状态。

特点：写命中延迟小，总线占用少，未保持一致性。



#### 多层次Cache

缘由：由于CPU时钟频率非常高，与主存的DRAM速度相差很大，虽然Cache的命中率达90％至95％以 上，但是一旦出现Cache未命中的情况，CPU要向DRAM存取时，性能将明显恶化。

结构：CPU和主存之间至少设置了一级缓存（L1 Cache）和二级缓存（L2 Cache），大部分还设置 了三级缓存（L3 Cache）。



##### 一级缓存（L1 Cache）

- 直接做在CPU内部，也称内部Cache;
- 所用存储器件**速度最快**，与CPU匹配；
- 但**容量小**；
- Pentium之后的CPU内部采用了数据和指令双通道Cache技术（哈佛结构）；
- 容量在32～128KB，或更大些。



##### 二级缓存（L2 Cache）

- 是**CPU和主存之间的缓存**;
- **速度**可以比L1 Cache低些；
- **容量**比L1 Cache大一个数量级以上；
- 最初时做在主板上，后与CPU芯片封装在一起，进一步提高了L2 Cache的速度；
- 容量在512KB～1MB，或更大些。



### 虚拟存储器

#### 问题起源

Cache-主存层次：解决**主存速度**问题。

主存-辅存层次：解决**主存容量**问题。 



#### 虚拟存储器的概念

定义：以透明方式**为程序提供**的、**比主存空间**大得多的存储空间。

- 透明方式：对程序员而言可忽略其存在，即仅需按程序地址访存；
- 存储单元：存储单元长度＝主存单元长度。

概念解析

- “虚拟存储器”：容量非常大的存储器**逻辑模型**，不是任何实际的物理存储器。
- “容量”：借助于磁盘等辅助存储器来扩大主存容量，使之为更大或更多的程序所使用。
- “物理地址”：实际主存单元的地址。
- “虚拟地址”：用户编程（即程序中出现）的地址（程序员看到的地址空间）。

**对“透明”的理解**：对用户是不可见的。



#### 虚拟存储器的基本原理

程序局部性原理：**主存-辅存层次**和**Cache-主存层次**用的**地址映射方法**和**替换策略**类似。

- 调入：把程序中最近常用的部分驻留在高速的存储器中；
- 调出：一旦这部分变得不常用了，把它们送回到低速的存储器中；
- 原则：这种调入调出是由硬件或操作系统完成的，对用户是透明的；
- 效果：力图使存储系统的性能接近高速存储器，价格接近低速存储器。

两种存储系统的区别：在虚拟存储器中未命中的性能损失要远大于cache系统中未命中的损失。

**注意**

1. Cache中的地址映射是实现主存地址和Cache地址之间的变换；
2. 虚拟存储器中的地址映射是实现虚拟地址与物理地址之间的变换。



#### 虚拟存储器的结构

结构：由**主存及辅存**实现，按虚拟地址访问。

特征：主存用作虚存的**缓存**，辅存用作主存的**后备存储器**。

本质：虚拟存储器是**面向软件**的存储器模型。



#### 虚拟存储器的组织

地址空间：虚存、主存、辅存。

三个地址空间：虚存、主存、辅存。

两种地址映射：虚存-主存、虚存-辅存。

交换区：(**临时配置**) 存放缓存区换出的内容，是**缓存区的延伸**(后备存储器)

工作过程：地址变换（含缺失处理）、访问主存、一致性保持。



#### 存储管理

虚存-主存的信息交换单位：程序段（大小可变）、主存页（大小固定）。

管理方式：段式、**页式**、段页式。

- 段式：按程序的逻辑结构划分成多个相对独立部分，如代码段、数据段、堆栈段等。
  - 优点：与程序自然分界对应；逻辑独立，便于编译、管理、修改和保护，也便于多道程序共享。
  - 缺点：容易在段间留下许多空余的零碎存储空间不好利用，造成浪费。
- **页式**：主存物理空间中划分出来的等长的固定区域。
  - 优点：起点和终点地址固定，方便构造页表，新页调入主存也很容易掌握，比段式空间浪费小。
  - 缺点：处理、保护和共享都不及段式来得方便。
- 段页式：分段和分页的结合，先按程序分段，段内再分成固定大小的页。信息交换以页为单位。
  - 优点：程序对主存的调入调出按页进行，同时又可按段实现共享和保护，兼备段和页的优点。
  - 缺点：在映射过程中需要多次查表。



#### 页表（Page Table, PT）的组织

页表的索引方法：虚页号。

页表项（Page Table Entry, PTE）的组织：**无需**标记字段。

页表长度：程序的最大页号。



#### 快表的组织

任务：地址变换的优化。

虚拟存储器的问题

- 性能分析：≤主存性能的一半。（地址变换≥1次访存）
- 组织优化：利用访问局部性，页表采用**层次结构**组织，在MMU中设置**页表缓冲器**。

TLB（Translation Lookaside Buffer）：旁路快表缓冲，也称为页表缓冲、地址变换高速缓存、快表。

- 存储管理方法：组/全相联映射、LRU算法、写回法策略。
- TLB条目组织：管理信息＋页表项信息。

地址变换过程：先访问TLB（CPU的Cache中），TLB缺失时才访问页表。